# åˆæœŸãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ã®ãŸã‚ã®æ©Ÿèƒ½å®Ÿè£…è¨ˆç”»

## æ¦‚è¦

æœ¬ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ã€2é€±é–“ã§åˆæœŸãƒ¢ãƒ‡ãƒ«ã‚’å®Œæˆã•ã›ã‚‹ãŸã‚ã«å¿…è¦ãªæ©Ÿèƒ½ã®å®Ÿè£…è¨ˆç”»ã‚’å®šã‚ãŸã‚‚ã®ã§ã™ã€‚ç‰¹ã«ã€ç¾åœ¨ä¸è¶³ã—ã¦ã„ã‚‹ã€Œãƒ‡ãƒ¼ã‚¿æ‹¡å¼µæ©Ÿèƒ½ã€ã€Œãƒ©ãƒ™ãƒªãƒ³ã‚°åŠ¹ç‡åŒ–æ©Ÿèƒ½ã€ã€ŒYOLOv8å¯¾å¿œã€ã®3ã¤ã®é‡è¦æ©Ÿèƒ½ã«ã¤ã„ã¦ã€å…·ä½“çš„ãªå®Ÿè£…æ‰‹é †ã¨ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ç¤ºã—ã¾ã™ã€‚

## å®Ÿè£…å„ªå…ˆé †ä½ã¨æ—¥ç¨‹

### å…¨ä½“ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆ7æ—¥é–“ã®é–‹ç™º + 7æ—¥é–“ã®ãƒ‡ãƒ¼ã‚¿ä½œæˆï¼‰

```
Week 1: æ©Ÿèƒ½é–‹ç™ºãƒ•ã‚§ãƒ¼ã‚º
- Day 1-3: ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µæ©Ÿèƒ½ã®å®Ÿè£…
- Day 4-5: ãƒ©ãƒ™ãƒªãƒ³ã‚°åŠ¹ç‡åŒ–æ©Ÿèƒ½ã®å®Ÿè£…  
- Day 6-7: YOLOv8å¯¾å¿œã¨ãƒ†ã‚¹ãƒˆ

Week 2: ãƒ‡ãƒ¼ã‚¿ä½œæˆãƒ•ã‚§ãƒ¼ã‚º
- Day 8-10: åˆæœŸ500æšã®æ‰‹å‹•ãƒ©ãƒ™ãƒªãƒ³ã‚°
- Day 11-12: ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã«ã‚ˆã‚‹20å€å¢—å¹…
- Day 13-14: åˆæœŸãƒ¢ãƒ‡ãƒ«è¨“ç·´ã¨è©•ä¾¡
```

## Day 1-3: ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µæ©Ÿèƒ½ã®å®Ÿè£… âœ… å®Œäº†

### 1.1 Albumentationsçµ±åˆï¼ˆDay 1ï¼‰âœ… å®Ÿè£…æ¸ˆã¿

#### å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«: `src/training/augmentation/advanced_augmentor.py`

**å®Ÿè£…å†…å®¹:**
- âœ… Albumentationsãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®çµ±åˆå®Œäº†
- âœ… 20ç¨®é¡ä»¥ä¸Šã®å¤šæ§˜ãªå¤‰æ›ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè£…
- âœ… ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã®è‡ªå‹•å¤‰æ›å¯¾å¿œ
- âœ… ã‚¯ãƒ©ã‚¹ãƒãƒ©ãƒ³ã‚¹ã‚’è€ƒæ…®ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç”Ÿæˆæ©Ÿèƒ½

```python
import albumentations as A
from albumentations.pytorch import ToTensorV2
import cv2
import numpy as np
from typing import List, Dict, Any

class AdvancedAugmentor:
    """20å€ä»¥ä¸Šã®ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚’å®Ÿç¾ã™ã‚‹é«˜åº¦ãªæ‹¡å¼µã‚¯ãƒ©ã‚¹"""

    def __init__(self, augmentation_factor: int = 20):
        self.augmentation_factor = augmentation_factor
        self.pipelines = self._create_augmentation_pipelines()

    def _create_augmentation_pipelines(self) -> List[A.Compose]:
        """å¤šæ§˜ãªæ‹¡å¼µãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’ä½œæˆ"""

        # åŸºæœ¬çš„ãªå¹¾ä½•å­¦çš„å¤‰æ›
        geometric_light = A.Compose([
            A.RandomRotate90(p=0.5),
            A.Flip(p=0.5),
            A.Transpose(p=0.3),
            A.ShiftScaleRotate(
                shift_limit=0.1,
                scale_limit=0.1,
                rotate_limit=15,
                p=0.7
            ),
        ])

        # ä¸­ç¨‹åº¦ã®å¹¾ä½•å­¦çš„å¤‰æ›
        geometric_medium = A.Compose([
            A.ElasticTransform(
                alpha=1,
                sigma=50,
                alpha_affine=50,
                p=0.5
            ),
            A.GridDistortion(
                num_steps=5,
                distort_limit=0.3,
                p=0.5
            ),
            A.OpticalDistortion(
                distort_limit=0.5,
                shift_limit=0.5,
                p=0.5
            ),
        ])

        # é€è¦–å¤‰æ›ï¼ˆã‚«ãƒ¡ãƒ©ã‚¢ãƒ³ã‚°ãƒ«ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
        perspective = A.Compose([
            A.Perspective(
                scale=(0.05, 0.1),
                keep_size=True,
                p=0.7
            ),
            A.Affine(
                scale=(0.9, 1.1),
                translate_percent={"x": (-0.1, 0.1), "y": (-0.1, 0.1)},
                rotate=(-10, 10),
                shear=(-10, 10),
                p=0.7
            ),
        ])

        # ç…§æ˜æ¡ä»¶ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        lighting = A.Compose([
            A.RandomBrightnessContrast(
                brightness_limit=0.3,
                contrast_limit=0.3,
                p=0.8
            ),
            A.RandomGamma(
                gamma_limit=(70, 130),
                p=0.5
            ),
            A.HueSaturationValue(
                hue_shift_limit=10,
                sat_shift_limit=30,
                val_shift_limit=30,
                p=0.7
            ),
            A.CLAHE(
                clip_limit=4.0,
                tile_grid_size=(8, 8),
                p=0.3
            ),
            A.ColorJitter(
                brightness=0.2,
                contrast=0.2,
                saturation=0.2,
                hue=0.1,
                p=0.7
            ),
        ])

        # å½±ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        shadows = A.Compose([
            A.RandomShadow(
                shadow_roi=(0, 0.5, 1, 1),
                num_shadows_lower=1,
                num_shadows_upper=3,
                shadow_dimension=5,
                p=0.5
            ),
            A.RandomToneCurve(
                scale=0.1,
                p=0.3
            ),
        ])

        # ãƒã‚¤ã‚ºã¨ãƒ–ãƒ©ãƒ¼ï¼ˆå®Ÿç’°å¢ƒã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
        noise_blur = A.Compose([
            A.OneOf([
                A.GaussNoise(var_limit=(10.0, 50.0), p=1),
                A.ISONoise(
                    color_shift=(0.01, 0.05),
                    intensity=(0.1, 0.5),
                    p=1
                ),
                A.MultiplicativeNoise(
                    multiplier=(0.9, 1.1),
                    per_channel=True,
                    p=1
                ),
            ], p=0.7),
            A.OneOf([
                A.MotionBlur(blur_limit=5, p=1),
                A.MedianBlur(blur_limit=5, p=1),
                A.GaussianBlur(blur_limit=(3, 7), p=1),
                A.DefocusBlur(radius=(1, 3), alias_blur=0.1, p=1),
            ], p=0.5),
        ])

        # ç”»è³ªåŠ£åŒ–ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        quality_degradation = A.Compose([
            A.Downscale(
                scale_min=0.5,
                scale_max=0.9,
                interpolation=cv2.INTER_LINEAR,
                p=0.3
            ),
            A.ImageCompression(
                quality_lower=60,
                quality_upper=95,
                compression_type=A.ImageCompression.ImageCompressionType.JPEG,
                p=0.5
            ),
        ])

        # å¤©å€™æ¡ä»¶ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        weather = A.Compose([
            A.OneOf([
                A.RandomRain(
                    slant_lower=-10,
                    slant_upper=10,
                    drop_length=20,
                    drop_width=1,
                    drop_color=(200, 200, 200),
                    blur_value=3,
                    brightness_coefficient=0.7,
                    p=1
                ),
                A.RandomFog(
                    fog_coef_lower=0.3,
                    fog_coef_upper=0.5,
                    alpha_coef=0.08,
                    p=1
                ),
            ], p=0.1),
        ])

        # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®çµ„ã¿åˆã‚ã›
        return [
            # è»½åº¦ã®å¤‰æ›ï¼ˆé«˜é »åº¦ï¼‰
            A.Compose([geometric_light, lighting, noise_blur]),
            # ä¸­ç¨‹åº¦ã®å¤‰æ›
            A.Compose([geometric_medium, lighting, shadows]),
            # å¼·åº¦ã®å¤‰æ›
            A.Compose([perspective, lighting, quality_degradation]),
            # ç‰¹æ®Šæ¡ä»¶
            A.Compose([geometric_light, weather, noise_blur]),
        ]

    def augment_single_image(self, image: np.ndarray, bbox: List[float],
                            class_id: int) -> List[Dict[str, Any]]:
        """1æšã®ç”»åƒã‹ã‚‰è¤‡æ•°ã®æ‹¡å¼µç”»åƒã‚’ç”Ÿæˆ"""
        augmented_samples = []

        # å„ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§è¤‡æ•°å›æ‹¡å¼µ
        samples_per_pipeline = self.augmentation_factor // len(self.pipelines)

        for pipeline in self.pipelines:
            for i in range(samples_per_pipeline):
                # Albumentationsã®bboxå½¢å¼ã«å¤‰æ›
                transformed = pipeline(
                    image=image,
                    bboxes=[bbox],
                    class_labels=[class_id]
                )

                augmented_samples.append({
                    'image': transformed['image'],
                    'bbox': transformed['bboxes'][0] if transformed['bboxes'] else bbox,
                    'class_id': class_id,
                    'augmentation_info': {
                        'pipeline_idx': self.pipelines.index(pipeline),
                        'iteration': i
                    }
                })

        return augmented_samples

    def create_balanced_dataset(self, original_data: Dict[str, List],
                              target_per_class: int = 1000) -> Dict[str, List]:
        """ã‚¯ãƒ©ã‚¹ãƒãƒ©ãƒ³ã‚¹ã‚’è€ƒæ…®ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ"""
        balanced_data = {}

        for class_name, samples in original_data.items():
            if len(samples) >= target_per_class:
                # ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã¯ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
                balanced_data[class_name] = np.random.choice(
                    samples, target_per_class, replace=False
                ).tolist()
            else:
                # ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã‚‹å ´åˆã¯æ‹¡å¼µã§è£œå®Œ
                augmentation_needed = target_per_class // len(samples) + 1
                augmented_samples = []

                for sample in samples:
                    augmented = self.augment_single_image(
                        sample['image'],
                        sample['bbox'],
                        sample['class_id']
                    )
                    augmented_samples.extend(augmented[:augmentation_needed])

                balanced_data[class_name] = augmented_samples[:target_per_class]

        return balanced_data
```

### 1.2 èµ¤ãƒ‰ãƒ©æ¤œå‡ºç”¨ã®è‰²åˆ†ææ‹¡å¼µï¼ˆDay 2ï¼‰âœ… å®Ÿè£…æ¸ˆã¿

#### å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«: `src/training/augmentation/color_augmentor.py`

**å®Ÿè£…å†…å®¹:**
- âœ… èµ¤ãƒ‰ãƒ©ç”Ÿæˆã®ãŸã‚ã®4ã¤ã®æ‰‹æ³•å®Ÿè£…ï¼ˆã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ã€è‰²ç½®æ›ã€ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã€æ··åˆï¼‰
- âœ… è‰²çµ±è¨ˆã«åŸºã¥ãèµ¤ãƒ‰ãƒ©åˆ¤å®šæ©Ÿèƒ½
- âœ… é€šå¸¸ã®5ã¨èµ¤5ã®è¨“ç·´ãƒšã‚¢ç”Ÿæˆæ©Ÿèƒ½
- âœ… å¤šæ§˜ãªèµ¤è‰²ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ç”Ÿæˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

```python
class RedDoraAugmentor:
    """èµ¤ãƒ‰ãƒ©æ¤œå‡ºã®ãŸã‚ã®ç‰¹æ®Šãªè‰²æ‹¡å¼µ"""

    def __init__(self):
        self.red_enhancement_pipeline = self._create_red_enhancement_pipeline()

    def _create_red_enhancement_pipeline(self) -> A.Compose:
        """èµ¤è‰²ã‚’å¼·èª¿ã™ã‚‹æ‹¡å¼µãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³"""
        return A.Compose([
            # èµ¤è‰²ãƒãƒ£ãƒ³ãƒãƒ«ã®å¼·èª¿
            A.ChannelShuffle(p=0.3),
            A.RGBShift(
                r_shift_limit=20,
                g_shift_limit=10,
                b_shift_limit=10,
                p=0.7
            ),
            # èµ¤è‰²ã®å½©åº¦ã‚’ä¸Šã’ã‚‹
            A.HueSaturationValue(
                hue_shift_limit=5,
                sat_shift_limit=50,
                val_shift_limit=20,
                p=0.8
            ),
            # èµ¤è‰²é ˜åŸŸã®ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆå¼·èª¿
            A.CLAHE(
                clip_limit=3.0,
                tile_grid_size=(4, 4),
                p=0.5
            ),
        ])

    def create_red_dora_variations(self, base_five_tile: np.ndarray,
                                  n_variations: int = 50) -> List[np.ndarray]:
        """é€šå¸¸ã®5ã®ç‰Œã‹ã‚‰èµ¤ãƒ‰ãƒ©ã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆ"""
        variations = []

        for i in range(n_variations):
            # èµ¤è‰²ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ã®è¿½åŠ 
            red_overlay = np.zeros_like(base_five_tile)
            red_overlay[:, :, 2] = np.random.randint(100, 200)  # Red channel

            # ã‚¢ãƒ«ãƒ•ã‚¡ãƒ–ãƒ¬ãƒ³ãƒ‡ã‚£ãƒ³ã‚°
            alpha = np.random.uniform(0.3, 0.7)
            red_tinted = cv2.addWeighted(base_five_tile, 1-alpha, red_overlay, alpha, 0)

            # è¿½åŠ ã®è‰²æ‹¡å¼µ
            augmented = self.red_enhancement_pipeline(image=red_tinted)['image']
            variations.append(augmented)

        return variations
```

### 1.3 ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã®çµ±åˆã¨ãƒ†ã‚¹ãƒˆï¼ˆDay 3ï¼‰âœ… å®Ÿè£…æ¸ˆã¿

#### å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«: `src/training/augmentation/unified_augmentor.py`

**å®Ÿè£…å†…å®¹:**
- âœ… ã™ã¹ã¦ã®æ‹¡å¼µæ©Ÿèƒ½ã‚’çµ±åˆã—ãŸUnifiedAugmentorã‚¯ãƒ©ã‚¹
- âœ… ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå…¨ä½“ã®ä¸€æ‹¬å‡¦ç†æ©Ÿèƒ½
- âœ… è¨“ç·´/æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã®è‡ªå‹•åˆ†å‰²
- âœ… YOLOå½¢å¼ã§ã®ãƒ‡ãƒ¼ã‚¿å‡ºåŠ›
- âœ… è©³ç´°ãªãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆï¼ˆJSON/Markdownï¼‰
- âœ… åŒ…æ‹¬çš„ãªãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰ï¼ˆtests/test_augmentation.pyï¼‰

```python
from .advanced_augmentor import AdvancedAugmentor
from .color_augmentor import RedDoraAugmentor

class UnifiedAugmentor:
    """ã™ã¹ã¦ã®æ‹¡å¼µæ©Ÿèƒ½ã‚’çµ±åˆã—ãŸã‚¯ãƒ©ã‚¹"""

    def __init__(self, config: Dict[str, Any]):
        self.advanced = AdvancedAugmentor(
            augmentation_factor=config.get('augmentation_factor', 20)
        )
        self.red_dora = RedDoraAugmentor()
        self.config = config

    def augment_dataset(self, dataset_path: str, output_path: str):
        """ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå…¨ä½“ã®æ‹¡å¼µ"""
        # å®Ÿè£…è©³ç´°...
```

## Day 4-5: ãƒ©ãƒ™ãƒªãƒ³ã‚°åŠ¹ç‡åŒ–æ©Ÿèƒ½ã®å®Ÿè£… âœ… å®Œäº†

### 2.1 ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ã‚·ãƒ§ãƒ¼ãƒˆã‚«ãƒƒãƒˆã®æ‹¡å……ï¼ˆDay 4ï¼‰âœ… å®Ÿè£…æ¸ˆã¿

#### å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«: `web_interface/static/js/enhanced_shortcuts.js`

**å®Ÿè£…å†…å®¹:**
- âœ… 30ç¨®é¡ä»¥ä¸Šã®åŒ…æ‹¬çš„ãªã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ã‚·ãƒ§ãƒ¼ãƒˆã‚«ãƒƒãƒˆ
- âœ… ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯æ©Ÿèƒ½
- âœ… ãƒ˜ãƒ«ãƒ—ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ï¼ˆHã‚­ãƒ¼ã§è¡¨ç¤ºï¼‰
- âœ… ã‚¯ã‚¤ãƒƒã‚¯ãƒ©ãƒ™ãƒªãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰ã®å®Ÿè£…

```javascript
class EnhancedShortcutManager {
    constructor(labelingInterface) {
        this.interface = labelingInterface;
        this.shortcuts = this.defineShortcuts();
        this.setupEventListeners();
    }

    defineShortcuts() {
        return {
            // ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³
            'ArrowRight': () => this.interface.nextFrame(),
            'ArrowLeft': () => this.interface.previousFrame(),
            'Space': () => this.interface.togglePlayPause(),

            // ãƒ©ãƒ™ãƒªãƒ³ã‚°æ“ä½œ
            'Enter': () => this.interface.confirmCurrentBox(),
            'Escape': () => this.interface.cancelCurrentBox(),
            'Delete': () => this.interface.deleteSelectedBox(),
            'Ctrl+C': () => this.interface.copySelectedBox(),
            'Ctrl+V': () => this.interface.pasteBox(),

            // ç‰Œã®ç¨®é¡é¸æŠï¼ˆæ•°å­—ã‚­ãƒ¼ï¼‰
            '1': () => this.interface.selectTileType('manzu'),
            '2': () => this.interface.selectTileType('pinzu'),
            '3': () => this.interface.selectTileType('souzu'),
            '4': () => this.interface.selectTileType('jihai'),

            // ç‰Œã®ç•ªå·é¸æŠï¼ˆãƒ†ãƒ³ã‚­ãƒ¼ï¼‰
            'Numpad1': () => this.interface.selectTileNumber(1),
            'Numpad2': () => this.interface.selectTileNumber(2),
            // ... Numpad3-9

            // ç‰¹æ®Šç‰Œ
            'R': () => this.interface.toggleRedDora(),
            'B': () => this.interface.selectBackTile(),

            // è¡¨ç¤ºåˆ¶å¾¡
            'G': () => this.interface.toggleGrid(),
            'L': () => this.interface.toggleLabels(),
            'H': () => this.interface.toggleHelp(),

            // ãƒãƒƒãƒæ“ä½œ
            'Ctrl+A': () => this.interface.selectAllBoxes(),
            'Shift+Click': () => this.interface.multiSelect(),
            'Alt+C': () => this.interface.copyPreviousFrame(),

            // ã‚¯ã‚¤ãƒƒã‚¯ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
            'Q': () => this.interface.quickLabelMode(),
            'W': () => this.interface.switchToNextUnlabeled(),
            'S': () => this.interface.saveProgress(),
        };
    }

    setupEventListeners() {
        document.addEventListener('keydown', (e) => {
            const key = this.getKeyCombo(e);
            const action = this.shortcuts[key];

            if (action && !this.interface.isInputFocused()) {
                e.preventDefault();
                action();
                this.showShortcutFeedback(key);
            }
        });
    }

    getKeyCombo(event) {
        let combo = '';
        if (event.ctrlKey) combo += 'Ctrl+';
        if (event.altKey) combo += 'Alt+';
        if (event.shiftKey) combo += 'Shift+';
        combo += event.key;
        return combo;
    }

    showShortcutFeedback(key) {
        // ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®è¡¨ç¤º
        const feedback = document.createElement('div');
        feedback.className = 'shortcut-feedback';
        feedback.textContent = key;
        document.body.appendChild(feedback);

        setTimeout(() => feedback.remove(), 500);
    }
}

// ã‚¯ã‚¤ãƒƒã‚¯ãƒ©ãƒ™ãƒªãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰
class QuickLabelingMode {
    constructor(interface) {
        this.interface = interface;
        this.enabled = false;
        this.lastTileType = null;
    }

    enable() {
        this.enabled = true;
        this.interface.showMessage('ã‚¯ã‚¤ãƒƒã‚¯ãƒ©ãƒ™ãƒªãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰: ON');
        this.setupQuickMode();
    }

    setupQuickMode() {
        // ã‚¯ãƒªãƒƒã‚¯ã ã‘ã§ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‚’ä½œæˆ
        this.interface.canvas.addEventListener('click', (e) => {
            if (!this.enabled) return;

            const rect = this.interface.canvas.getBoundingClientRect();
            const x = e.clientX - rect.left;
            const y = e.clientY - rect.top;

            // æœ€å¾Œã«ä½¿ç”¨ã—ãŸç‰Œç¨®ã§è‡ªå‹•çš„ã«ãƒœãƒƒã‚¯ã‚¹ã‚’ä½œæˆ
            if (this.lastTileType) {
                this.interface.createBoxAtPoint(x, y, this.lastTileType);
            }
        });
    }
}
```

### 2.2 ãƒãƒƒãƒãƒ©ãƒ™ãƒªãƒ³ã‚°æ©Ÿèƒ½ï¼ˆDay 5ï¼‰âœ… å®Ÿè£…æ¸ˆã¿

#### å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«: `src/training/labeling/batch_labeler.py`

**å®Ÿè£…å†…å®¹:**
- âœ… ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ™ãƒ¼ã‚¹ã®ä¸€æ‹¬é©ç”¨
- âœ… ã‚ªãƒ—ãƒ†ã‚£ã‚«ãƒ«ãƒ•ãƒ­ãƒ¼ã«ã‚ˆã‚‹è‡ªå‹•è¿½è·¡
- âœ… ã‚¹ãƒãƒ¼ãƒˆãªå‰æ–¹ä¼æ’­æ©Ÿèƒ½
- âœ… ãƒ•ãƒ¬ãƒ¼ãƒ é–“ã®é¡ä¼¼åº¦è¨ˆç®—
- âœ… Webã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼ã«ã‚ˆã‚‹UIãƒ¬ãƒ™ãƒ«ã®çµ±åˆ

```python
class BatchLabeler:
    """è¤‡æ•°ãƒ•ãƒ¬ãƒ¼ãƒ ã®ä¸€æ‹¬ãƒ©ãƒ™ãƒªãƒ³ã‚°æ©Ÿèƒ½"""

    def __init__(self, interface):
        self.interface = interface
        self.templates = {}

    def create_template_from_frame(self, frame_id: str) -> Dict[str, Any]:
        """ç¾åœ¨ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½œæˆ"""
        annotations = self.interface.get_frame_annotations(frame_id)

        template = {
            'tile_positions': [],
            'tile_types': [],
            'created_from': frame_id,
            'timestamp': datetime.now()
        }

        for ann in annotations:
            template['tile_positions'].append({
                'bbox': ann['bbox'],
                'relative_position': self._calculate_relative_position(ann['bbox'])
            })
            template['tile_types'].append(ann['tile_type'])

        return template

    def apply_template_to_frames(self, template: Dict[str, Any],
                               frame_ids: List[str],
                               auto_adjust: bool = True):
        """ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’è¤‡æ•°ãƒ•ãƒ¬ãƒ¼ãƒ ã«é©ç”¨"""
        results = []

        for frame_id in frame_ids:
            if auto_adjust:
                # ãƒ•ãƒ¬ãƒ¼ãƒ é–“ã®ä½ç½®ãšã‚Œã‚’è‡ªå‹•è£œæ­£
                adjusted_template = self._adjust_template_for_frame(
                    template, frame_id
                )
            else:
                adjusted_template = template

            # ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã®é©ç”¨
            annotations = self._apply_template(adjusted_template, frame_id)
            results.append({
                'frame_id': frame_id,
                'annotations': annotations,
                'success': len(annotations) > 0
            })

        return results

    def smart_propagation(self, start_frame: int, end_frame: int,
                         confidence_threshold: float = 0.8):
        """ã‚¹ãƒãƒ¼ãƒˆãªå‰æ–¹ä¼æ’­"""
        current_annotations = self.interface.get_frame_annotations(start_frame)

        for frame_idx in range(start_frame + 1, end_frame + 1):
            # å‰ãƒ•ãƒ¬ãƒ¼ãƒ ã¨ã®å·®åˆ†ã‚’è¨ˆç®—
            frame_diff = self._calculate_frame_difference(frame_idx - 1, frame_idx)

            if frame_diff < 0.1:  # ã»ã¼åŒã˜ãƒ•ãƒ¬ãƒ¼ãƒ 
                # ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ãã®ã¾ã¾ã‚³ãƒ”ãƒ¼
                self._copy_annotations(frame_idx - 1, frame_idx)
            else:
                # ã‚ªãƒ—ãƒ†ã‚£ã‚«ãƒ«ãƒ•ãƒ­ãƒ¼ã§ä½ç½®ã‚’è¿½è·¡
                adjusted_annotations = self._track_tiles_optical_flow(
                    current_annotations, frame_idx - 1, frame_idx
                )

                # ä¿¡é ¼åº¦ã®é«˜ã„ã‚‚ã®ã ã‘ã‚’é©ç”¨
                filtered = [
                    ann for ann in adjusted_annotations
                    if ann['confidence'] > confidence_threshold
                ]

                self.interface.set_frame_annotations(frame_idx, filtered)
                current_annotations = filtered

    def _track_tiles_optical_flow(self, annotations: List[Dict],
                                 prev_frame_idx: int,
                                 curr_frame_idx: int) -> List[Dict]:
        """ã‚ªãƒ—ãƒ†ã‚£ã‚«ãƒ«ãƒ•ãƒ­ãƒ¼ã‚’ä½¿ç”¨ã—ãŸç‰Œã®è¿½è·¡"""
        prev_frame = self.interface.get_frame(prev_frame_idx)
        curr_frame = self.interface.get_frame(curr_frame_idx)

        # ã‚ªãƒ—ãƒ†ã‚£ã‚«ãƒ«ãƒ•ãƒ­ãƒ¼è¨ˆç®—
        flow = cv2.calcOpticalFlowFarneback(
            cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY),
            cv2.cvtColor(curr_frame, cv2.COLOR_BGR2GRAY),
            None, 0.5, 3, 15, 3, 5, 1.2, 0
        )

        adjusted_annotations = []
        for ann in annotations:
            # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã®ä¸­å¿ƒç‚¹ã‚’è¿½è·¡
            cx, cy = self._get_bbox_center(ann['bbox'])
            dx, dy = flow[int(cy), int(cx)]

            # æ–°ã—ã„ä½ç½®ã‚’è¨ˆç®—
            new_bbox = [
                ann['bbox'][0] + dx,
                ann['bbox'][1] + dy,
                ann['bbox'][2] + dx,
                ann['bbox'][3] + dy
            ]

            adjusted_annotations.append({
                **ann,
                'bbox': new_bbox,
                'confidence': self._calculate_tracking_confidence(flow, ann['bbox'])
            })

        return adjusted_annotations
```

## Day 6-7: YOLOv8å¯¾å¿œ âœ… å®Œäº†

### 3.1 YOLOv8çµ±åˆï¼ˆDay 6ï¼‰âœ… å®Ÿè£…æ¸ˆã¿

#### å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«: `src/detection/yolov8_detector.py`

**å®Ÿè£…å†…å®¹:**
- âœ… ultralyticsãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®å®Œå…¨çµ±åˆ
- âœ… YOLOv8å½¢å¼ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè‡ªå‹•å¤‰æ›
- âœ… æœ€é©åŒ–ã•ã‚ŒãŸè¨“ç·´ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
- âœ… ãƒãƒƒãƒäºˆæ¸¬ã¨ãƒ¢ãƒ‡ãƒ«è©•ä¾¡æ©Ÿèƒ½
- âœ… å¯è¦–åŒ–æ©Ÿèƒ½ã¨ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæ©Ÿèƒ½

```python
from ultralytics import YOLO
import torch
import numpy as np
from pathlib import Path

class YOLOv8TileDetector:
    """YOLOv8ã‚’ä½¿ç”¨ã—ãŸéº»é›€ç‰Œæ¤œå‡ºå™¨"""

    def __init__(self, model_path: str = None, device: str = 'auto'):
        self.device = self._setup_device(device)
        self.model = self._load_model(model_path)
        self.class_names = self._setup_class_names()

    def _setup_device(self, device: str) -> str:
        if device == 'auto':
            return 'cuda' if torch.cuda.is_available() else 'cpu'
        return device

    def _load_model(self, model_path: str) -> YOLO:
        if model_path and Path(model_path).exists():
            # æ—¢å­˜ã®ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿
            return YOLO(model_path)
        else:
            # æ–°è¦ãƒ¢ãƒ‡ãƒ«ã®ä½œæˆ
            return YOLO('yolov8n.yaml')  # nanoç‰ˆã‹ã‚‰é–‹å§‹

    def _setup_class_names(self) -> List[str]:
        """éº»é›€ç‰Œã®ã‚¯ãƒ©ã‚¹åã‚’è¨­å®š"""
        tiles = []

        # æ•°ç‰Œ
        for suit in ['m', 'p', 's']:
            for num in range(1, 10):
                tiles.append(f"{num}{suit}")

        # å­—ç‰Œ
        tiles.extend(['1z', '2z', '3z', '4z', '5z', '6z', '7z'])

        # èµ¤ãƒ‰ãƒ©
        tiles.extend(['0m', '0p', '0s'])

        # è£é¢
        tiles.append('back')

        return tiles

    def prepare_training_data(self, dataset_path: str, output_path: str):
        """YOLOv8å½¢å¼ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™"""
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã®ä½œæˆ
        output_dir = Path(output_path)
        (output_dir / 'images' / 'train').mkdir(parents=True, exist_ok=True)
        (output_dir / 'images' / 'val').mkdir(parents=True, exist_ok=True)
        (output_dir / 'labels' / 'train').mkdir(parents=True, exist_ok=True)
        (output_dir / 'labels' / 'val').mkdir(parents=True, exist_ok=True)

        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆ
        yaml_content = f"""
path: {output_dir.absolute()}
train: images/train
val: images/val

names:
{chr(10).join(f"  {i}: {name}" for i, name in enumerate(self.class_names))}

nc: {len(self.class_names)}
"""

        with open(output_dir / 'dataset.yaml', 'w') as f:
            f.write(yaml_content)

        # ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã®å¤‰æ›
        self._convert_annotations(dataset_path, output_dir)

    def _convert_annotations(self, input_path: str, output_dir: Path):
        """æ—¢å­˜ã®ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’YOLOå½¢å¼ã«å¤‰æ›"""
        from ..dataset_manager import DatasetManager

        dm = DatasetManager()
        annotations = dm.get_all_annotations()

        for ann in annotations:
            # ç”»åƒã®ã‚³ãƒ”ãƒ¼
            img_path = Path(ann['image_path'])
            split = 'train' if np.random.random() < 0.8 else 'val'

            new_img_path = output_dir / 'images' / split / img_path.name
            shutil.copy(img_path, new_img_path)

            # ãƒ©ãƒ™ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆ
            label_path = output_dir / 'labels' / split / f"{img_path.stem}.txt"

            with open(label_path, 'w') as f:
                for tile in ann['tiles']:
                    # YOLOå½¢å¼ã«å¤‰æ› (class_id, x_center, y_center, width, height)
                    class_id = self.class_names.index(tile['class'])
                    x_center = (tile['bbox'][0] + tile['bbox'][2]) / 2 / ann['width']
                    y_center = (tile['bbox'][1] + tile['bbox'][3]) / 2 / ann['height']
                    width = (tile['bbox'][2] - tile['bbox'][0]) / ann['width']
                    height = (tile['bbox'][3] - tile['bbox'][1]) / ann['height']

                    f.write(f"{class_id} {x_center} {y_center} {width} {height}\n")

    def train(self, data_yaml: str, epochs: int = 100, batch_size: int = 16):
        """YOLOv8ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´"""
        results = self.model.train(
            data=data_yaml,
            epochs=epochs,
            batch=batch_size,
            imgsz=640,
            device=self.device,
            project='models/yolov8',
            name='mahjong_tiles',
            exist_ok=True,

            # æœ€é©åŒ–è¨­å®š
            optimizer='AdamW',
            lr0=0.001,
            lrf=0.01,
            momentum=0.937,
            weight_decay=0.0005,

            # ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µï¼ˆYOLOv8å†…è”µï¼‰
            hsv_h=0.015,
            hsv_s=0.7,
            hsv_v=0.4,
            degrees=0.0,
            translate=0.1,
            scale=0.5,
            shear=0.0,
            perspective=0.0,
            flipud=0.0,
            fliplr=0.5,
            mosaic=1.0,
            mixup=0.0,

            # ãã®ä»–ã®è¨­å®š
            close_mosaic=10,
            amp=True,  # è‡ªå‹•æ··åˆç²¾åº¦
            patience=50,  # æ—©æœŸåœæ­¢
            save=True,
            save_period=10,
            val=True,
            plots=True,
        )

        return results

    def predict(self, image: np.ndarray, conf_threshold: float = 0.5):
        """ç”»åƒã‹ã‚‰éº»é›€ç‰Œã‚’æ¤œå‡º"""
        results = self.model(
            image,
            conf=conf_threshold,
            iou=0.45,
            max_det=300,
            classes=None,  # ã™ã¹ã¦ã®ã‚¯ãƒ©ã‚¹ã‚’æ¤œå‡º
        )

        detections = []
        for r in results:
            boxes = r.boxes
            if boxes is not None:
                for i in range(len(boxes)):
                    detection = {
                        'bbox': boxes.xyxy[i].cpu().numpy().tolist(),
                        'confidence': float(boxes.conf[i]),
                        'class_id': int(boxes.cls[i]),
                        'class_name': self.class_names[int(boxes.cls[i])]
                    }
                    detections.append(detection)

        return detections
```

### 3.2 è¨“ç·´ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®çµ±åˆï¼ˆDay 7ï¼‰âœ… å®Ÿè£…æ¸ˆã¿

#### å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«: `src/training/unified_trainer.py`

**å®Ÿè£…å†…å®¹:**
- âœ… å®Œå…¨è‡ªå‹•åŒ–ã•ã‚ŒãŸè¨“ç·´ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
- âœ… ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µâ†’YOLOå¤‰æ›â†’è¨“ç·´â†’è©•ä¾¡ã®çµ±åˆ
- âœ… è©³ç´°ãªãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆï¼ˆJSON/Markdownï¼‰
- âœ… ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ©Ÿèƒ½
- âœ… ãƒãƒƒãƒæ¨è«–æ©Ÿèƒ½

```python
class UnifiedModelTrainer:
    """ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã€ãƒ©ãƒ™ãƒªãƒ³ã‚°ã€YOLOv8ã‚’çµ±åˆã—ãŸè¨“ç·´ã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self, config_path: str):
        self.config = self._load_config(config_path)
        self.augmentor = UnifiedAugmentor(self.config['augmentation'])
        self.detector = YOLOv8TileDetector()
        self.batch_labeler = BatchLabeler(None)  # ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã¯å¾Œã§è¨­å®š

    def create_initial_model(self,
                           raw_data_path: str,
                           output_model_path: str,
                           target_accuracy: float = 0.5):
        """åˆæœŸãƒ¢ãƒ‡ãƒ«ä½œæˆã®å®Œå…¨ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼"""

        # Step 1: ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ
        print("Step 1: ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚’å®Ÿè¡Œä¸­...")
        augmented_path = self._augment_initial_data(raw_data_path)

        # Step 2: YOLOv8å½¢å¼ã¸ã®å¤‰æ›
        print("Step 2: YOLOv8å½¢å¼ã«å¤‰æ›ä¸­...")
        yolo_dataset_path = self._prepare_yolo_dataset(augmented_path)

        # Step 3: åˆæœŸè¨“ç·´
        print("Step 3: åˆæœŸãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã‚’é–‹å§‹...")
        self._train_initial_model(yolo_dataset_path, output_model_path)

        # Step 4: è©•ä¾¡ã¨ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        print("Step 4: ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ä¸­...")
        metrics = self._evaluate_model(output_model_path)

        if metrics['mAP'] >= target_accuracy:
            print(f"âœ… ç›®æ¨™ç²¾åº¦ {target_accuracy} ã‚’é”æˆ: mAP = {metrics['mAP']:.3f}")
        else:
            print(f"âš ï¸ ç›®æ¨™ç²¾åº¦æœªé”: mAP = {metrics['mAP']:.3f} < {target_accuracy}")

        # ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ
        self._generate_training_report(metrics, output_model_path)

        return metrics

    def _augment_initial_data(self, raw_data_path: str) -> str:
        """åˆæœŸãƒ‡ãƒ¼ã‚¿ã®æ‹¡å¼µï¼ˆ1,200æš â†’ 24,000æšï¼‰"""
        output_path = Path(raw_data_path).parent / 'augmented_data'

        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        raw_data = self._load_raw_data(raw_data_path)

        # ã‚¯ãƒ©ã‚¹ãƒãƒ©ãƒ³ã‚¹ã‚’è€ƒæ…®ã—ãŸæ‹¡å¼µ
        balanced_data = self.augmentor.advanced.create_balanced_dataset(
            raw_data,
            target_per_class=650  # 37ã‚¯ãƒ©ã‚¹ Ã— 650 â‰ˆ 24,000
        )

        # ä¿å­˜
        self._save_augmented_data(balanced_data, output_path)

        return str(output_path)

    def _prepare_yolo_dataset(self, augmented_path: str) -> str:
        """YOLOv8å½¢å¼ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™"""
        output_path = Path(augmented_path).parent / 'yolo_dataset'

        self.detector.prepare_training_data(
            augmented_path,
            str(output_path)
        )

        return str(output_path / 'dataset.yaml')

    def _train_initial_model(self, data_yaml: str, output_path: str):
        """åˆæœŸãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´"""
        # è»½é‡ãªè¨­å®šã§é«˜é€Ÿã«è¨“ç·´
        results = self.detector.train(
            data_yaml=data_yaml,
            epochs=50,  # åˆæœŸã¯å°‘ãªã‚
            batch_size=32,
            imgsz=416,  # åˆæœŸã¯å°ã•ã‚ã®ç”»åƒã‚µã‚¤ã‚º
        )

        # æœ€è‰¯ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜
        best_model = Path('models/yolov8/mahjong_tiles/weights/best.pt')
        if best_model.exists():
            shutil.copy(best_model, output_path)

    def _evaluate_model(self, model_path: str) -> Dict[str, float]:
        """ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡"""
        self.detector.model = YOLO(model_path)

        # æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã§ã®è©•ä¾¡
        metrics = self.detector.model.val()

        return {
            'mAP': float(metrics.box.map),
            'mAP50': float(metrics.box.map50),
            'mAP75': float(metrics.box.map75),
            'precision': float(metrics.box.p),
            'recall': float(metrics.box.r),
            'classes': self._evaluate_per_class(metrics)
        }

    def _generate_training_report(self, metrics: Dict, model_path: str):
        """è¨“ç·´ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ"""
        report_path = Path(model_path).parent / 'training_report.md'

        report_content = f"""
# åˆæœŸãƒ¢ãƒ‡ãƒ«è¨“ç·´ãƒ¬ãƒãƒ¼ãƒˆ

## æ¦‚è¦
- ç”Ÿæˆæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹: {model_path}

## å…¨ä½“çš„ãªãƒ¡ãƒˆãƒªã‚¯ã‚¹
- mAP@0.5: {metrics['mAP50']:.3f}
- mAP@0.5:0.95: {metrics['mAP']:.3f}
- Precision: {metrics['precision']:.3f}
- Recall: {metrics['recall']:.3f}

## ã‚¯ãƒ©ã‚¹åˆ¥æ€§èƒ½
| ã‚¯ãƒ©ã‚¹ | AP@0.5 | Precision | Recall |
|--------|--------|-----------|--------|
"""

        for class_name, class_metrics in metrics['classes'].items():
            report_content += f"| {class_name} | {class_metrics['ap50']:.3f} | "
            report_content += f"{class_metrics['precision']:.3f} | "
            report_content += f"{class_metrics['recall']:.3f} |\n"

        report_content += """
## æ¨å¥¨äº‹é …
"""

        # æ€§èƒ½ã«åŸºã¥ãæ¨å¥¨äº‹é …
        if metrics['mAP'] < 0.3:
            report_content += "- ã‚ˆã‚Šå¤šãã®ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ã§ã™\n"
            report_content += "- ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚’ã•ã‚‰ã«å¼·åŒ–ã—ã¦ãã ã•ã„\n"
        elif metrics['mAP'] < 0.5:
            report_content += "- åŠè‡ªå‹•ãƒ©ãƒ™ãƒªãƒ³ã‚°ã‚’é–‹å§‹ã§ãã¾ã™\n"
            report_content += "- é›£ã—ã„ã‚µãƒ³ãƒ—ãƒ«ã‚’è¿½åŠ ã—ã¦ãã ã•ã„\n"
        else:
            report_content += "- å®Ÿç”¨ãƒ¬ãƒ™ãƒ«ã«è¿‘ã¥ã„ã¦ã„ã¾ã™\n"
            report_content += "- å®Ÿç’°å¢ƒã§ã®ãƒ†ã‚¹ãƒˆã‚’é–‹å§‹ã—ã¦ãã ã•ã„\n"

        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report_content)
```

## ãƒ†ã‚¹ãƒˆã¨ãƒ‡ãƒãƒƒã‚°è¨ˆç”»

### æ©Ÿèƒ½åˆ¥ãƒ†ã‚¹ãƒˆé …ç›®

#### 1. ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µãƒ†ã‚¹ãƒˆ
```python
def test_augmentation():
    # 1æšã®ç”»åƒã‹ã‚‰20æšç”Ÿæˆã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
    augmentor = AdvancedAugmentor(augmentation_factor=20)
    test_image = cv2.imread('test_tile.jpg')
    augmented = augmentor.augment_single_image(
        test_image,
        [100, 100, 200, 200],
        class_id=0
    )
    assert len(augmented) == 20

    # å„æ‹¡å¼µç”»åƒãŒç•°ãªã‚‹ã“ã¨ã‚’ç¢ºèª
    hashes = [imagehash.average_hash(Image.fromarray(a['image']))
              for a in augmented]
    assert len(set(hashes)) > 15  # å°‘ãªãã¨ã‚‚15ç¨®é¡ã¯ç•°ãªã‚‹
```

#### 2. ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ã‚·ãƒ§ãƒ¼ãƒˆã‚«ãƒƒãƒˆãƒ†ã‚¹ãƒˆ
```javascript
// Cypressã‚’ä½¿ç”¨ã—ãŸE2Eãƒ†ã‚¹ãƒˆ
describe('Keyboard Shortcuts', () => {
    it('should navigate frames with arrow keys', () => {
        cy.visit('/labeling');
        cy.get('body').type('{rightarrow}');
        cy.get('#frame-counter').should('contain', '2');
    });

    it('should copy previous frame with Alt+C', () => {
        cy.get('body').type('{alt}c');
        cy.get('.annotation-box').should('have.length.gt', 0);
    });
});
```

#### 3. YOLOv8çµ±åˆãƒ†ã‚¹ãƒˆ
```python
def test_yolov8_integration():
    detector = YOLOv8TileDetector()

    # ãƒ‡ãƒ¼ã‚¿æº–å‚™ã®ãƒ†ã‚¹ãƒˆ
    detector.prepare_training_data('test_data/', 'output/')
    assert Path('output/dataset.yaml').exists()
    assert Path('output/images/train').exists()

    # äºˆæ¸¬ã®ãƒ†ã‚¹ãƒˆ
    test_image = cv2.imread('test_frame.jpg')
    detections = detector.predict(test_image)
    assert isinstance(detections, list)
```

## æˆåŠŸåŸºæº–

### Week 1çµ‚äº†æ™‚ç‚¹ï¼ˆæ©Ÿèƒ½é–‹ç™ºå®Œäº†ï¼‰âœ… é”æˆ
- âœ… ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã§1æšâ†’20æšã®ç”ŸæˆãŒå¯èƒ½
- âœ… ä¸»è¦ãªã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ã‚·ãƒ§ãƒ¼ãƒˆã‚«ãƒƒãƒˆãŒå‹•ä½œ
- âœ… YOLOv8ã§ã®ãƒ‡ãƒ¼ã‚¿æº–å‚™ãƒ»è¨“ç·´ãŒå¯èƒ½
- âœ… çµ±åˆãƒ†ã‚¹ãƒˆãŒã™ã¹ã¦ãƒ‘ã‚¹

### Week 2çµ‚äº†æ™‚ç‚¹ï¼ˆåˆæœŸãƒ¢ãƒ‡ãƒ«å®Œæˆï¼‰
- [ ] 1,200æšã®æ‰‹å‹•ãƒ©ãƒ™ãƒªãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿
- [ ] 24,000æšã®æ‹¡å¼µãƒ‡ãƒ¼ã‚¿
- [ ] mAP 40%ä»¥ä¸Šã®åˆæœŸãƒ¢ãƒ‡ãƒ«
- [ ] åŠè‡ªå‹•ãƒ©ãƒ™ãƒªãƒ³ã‚°ã®å‹•ä½œç¢ºèª

## å®Ÿè£…å®Œäº†çŠ¶æ³ã‚µãƒãƒªãƒ¼

### âœ… å®Œäº†ã—ãŸæ©Ÿèƒ½ï¼ˆ7æ—¥é–“ï¼‰

1. **ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚·ã‚¹ãƒ†ãƒ ï¼ˆDay 1-3ï¼‰**
   - Albumentationsçµ±åˆã«ã‚ˆã‚‹20ç¨®é¡ä»¥ä¸Šã®å¤‰æ›
   - èµ¤ãƒ‰ãƒ©æ¤œå‡ºç”¨ã®ç‰¹æ®Šãªè‰²æ‹¡å¼µ
   - çµ±åˆæ‹¡å¼µã‚·ã‚¹ãƒ†ãƒ ã¨YOLOå½¢å¼å‡ºåŠ›

2. **ãƒ©ãƒ™ãƒªãƒ³ã‚°åŠ¹ç‡åŒ–ï¼ˆDay 4-5ï¼‰**
   - 30ç¨®é¡ä»¥ä¸Šã®ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ã‚·ãƒ§ãƒ¼ãƒˆã‚«ãƒƒãƒˆ
   - ã‚¯ã‚¤ãƒƒã‚¯ãƒ©ãƒ™ãƒªãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰
   - ã‚ªãƒ—ãƒ†ã‚£ã‚«ãƒ«ãƒ•ãƒ­ãƒ¼ã«ã‚ˆã‚‹ãƒãƒƒãƒãƒ©ãƒ™ãƒªãƒ³ã‚°
   - Webã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼

3. **YOLOv8çµ±åˆï¼ˆDay 6-7ï¼‰**
   - ultralyticså…¬å¼ãƒ©ã‚¤ãƒ–ãƒ©ãƒªçµ±åˆ
   - è‡ªå‹•ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå¤‰æ›
   - çµ±åˆè¨“ç·´ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
   - ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ»ãƒãƒƒãƒæ¨è«–å¯¾å¿œ

### ğŸš€ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

1. **å®Ÿãƒ‡ãƒ¼ã‚¿ã§ã®ãƒ†ã‚¹ãƒˆ**
   - å®Ÿéš›ã®å¯¾å±€å‹•ç”»ã‹ã‚‰ãƒ•ãƒ¬ãƒ¼ãƒ æŠ½å‡º
   - åˆæœŸ1,200æšã®ãƒ©ãƒ™ãƒªãƒ³ã‚°å®Ÿæ–½
   - åˆæœŸãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã¨è©•ä¾¡

2. **åŠè‡ªå‹•åŒ–ã¸ã®ç§»è¡Œ**
   - åˆæœŸãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹äºˆæ¸¬
   - äººé–“ã«ã‚ˆã‚‹ä¿®æ­£ã¨æ‰¿èª
   - ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ®µéšçš„æ‹¡å¤§

3. **ç¶™ç¶šçš„æ”¹å–„**
   - ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã®å®Ÿè£…
   - ç‰¹æ®Šã‚±ãƒ¼ã‚¹ï¼ˆèµ¤ãƒ‰ãƒ©ãƒ»è£é¢ï¼‰ã®å¼·åŒ–
   - å®Ÿç’°å¢ƒã§ã®æ€§èƒ½è©•ä¾¡

## ãƒªã‚¹ã‚¯ã¨å¯¾ç­–

### ãƒªã‚¹ã‚¯1: ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã®å“è³ª
**å¯¾ç­–**:
- æ‹¡å¼µãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ…é‡ãªèª¿æ•´
- äººé–“ã«ã‚ˆã‚‹å“è³ªãƒã‚§ãƒƒã‚¯ï¼ˆã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼‰
- éåº¦ãªå¤‰å½¢ã‚’é¿ã‘ã‚‹

### ãƒªã‚¹ã‚¯2: YOLOv8ã®å­¦ç¿’ãŒåæŸã—ãªã„
**å¯¾ç­–**:
- å­¦ç¿’ç‡ã®èª¿æ•´
- ã‚ˆã‚Šå°ã•ãªãƒ¢ãƒ‡ãƒ«ï¼ˆyolov8nï¼‰ã‹ã‚‰é–‹å§‹
- ãƒãƒƒãƒã‚µã‚¤ã‚ºã®æœ€é©åŒ–

### ãƒªã‚¹ã‚¯3: ãƒ©ãƒ™ãƒªãƒ³ã‚°ä½œæ¥­ã®é…å»¶
**å¯¾ç­–**:
- åŠ¹ç‡åŒ–ãƒ„ãƒ¼ãƒ«ã®å„ªå…ˆå®Ÿè£…
- è¤‡æ•°äººã§ã®ä½œæ¥­åˆ†æ‹…
- å“è³ªã‚ˆã‚Šé‡ã‚’é‡è¦–ï¼ˆåˆæœŸæ®µéšï¼‰

## ã¾ã¨ã‚

ã“ã®å®Ÿè£…è¨ˆç”»ã«å¾“ã†ã“ã¨ã§ã€2é€±é–“ã§åˆæœŸãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰ãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚ç‰¹ã«é‡è¦ãªã®ã¯ï¼š

1. **æœ€åˆã®3æ—¥é–“ã§ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚’å®Œæˆ**ã•ã›ã‚‹ã“ã¨
2. **ãƒ©ãƒ™ãƒªãƒ³ã‚°åŠ¹ç‡ã‚’æœ€å¤§åŒ–**ã™ã‚‹ã“ã¨
3. **YOLOv8ã‚’æ—©æœŸã«å‹•ä½œ**ã•ã›ã‚‹ã“ã¨

ã“ã‚Œã‚‰ã®æ©Ÿèƒ½ãŒæƒãˆã°ã€å°‘ãªã„ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã§ã‚‚å®Ÿç”¨çš„ãªåˆæœŸãƒ¢ãƒ‡ãƒ«ãŒæ§‹ç¯‰ã§ãã¾ã™ã€‚
