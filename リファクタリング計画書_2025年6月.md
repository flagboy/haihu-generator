# 麻雀牌譜作成システム リファクタリング計画書
## 2025年6月版

## エグゼクティブサマリー

### 現状分析
本システムは機能的に完成していますが、以下の技術的負債が蓄積しています：

1. **巨大クラス問題**
   - `model_evaluator.py` (898行)
   - `quality_validator.py` (771行)
   - `learning_scheduler.py` (656行)
   - 単一責任原則に違反し、保守性が低下

2. **テストカバレッジ問題**
   - 全体カバレッジ: 54.19%
   - 重要モジュールの低カバレッジ: gpu_optimizer.py (8.43%), model_manager.py (18.43%)

3. **パフォーマンス問題**
   - CI環境でのテスト実行時間が長い（約4-5分）
   - キャッシュ効率が期待値を下回る

4. **アーキテクチャ問題**
   - 天鳳JSON形式と他形式が混在
   - 密結合なコンポーネント
   - 重複コードの存在

### リファクタリング目標
1. **コード品質向上**: 各クラス500行以下、テストカバレッジ80%以上
2. **パフォーマンス改善**: 処理速度20-30%向上
3. **保守性向上**: 単一責任原則の徹底、疎結合化
4. **天鳳JSON形式特化**: 他形式サポートの削除による簡素化

## フェーズ1: 即座に対応すべき項目（第1-2週）

### 1.1 巨大クラスの分割

#### model_evaluator.py (898行) の分割

```python
# 分割案
src/training/learning/evaluation/
├── __init__.py
├── evaluator_base.py          # 基底クラスと共通機能
├── metrics_calculator.py       # メトリクス計算
├── confusion_analyzer.py       # 混同行列分析
├── visualization_generator.py  # 可視化機能
├── report_generator.py        # レポート生成
└── model_comparator.py        # モデル比較機能
```

**実装例**:
```python
# evaluator_base.py
class BaseEvaluator(ABC):
    """評価器の基底クラス"""
    def __init__(self, config_manager: ConfigManager):
        self.config = config_manager
        self.logger = get_logger(__name__)

    @abstractmethod
    def evaluate(self, model: Any, dataset: Any) -> EvaluationResult:
        pass

# metrics_calculator.py
class MetricsCalculator:
    """メトリクス計算専用クラス"""
    def calculate_accuracy(self, predictions: np.ndarray, labels: np.ndarray) -> float:
        return np.mean(predictions == labels)

    def calculate_precision_recall_f1(self, predictions: np.ndarray, labels: np.ndarray) -> Dict[str, float]:
        # 実装
```

#### quality_validator.py (771行) の分割

```python
# 分割案
src/validation/validators/
├── __init__.py
├── structure_validator.py     # 構造検証
├── content_validator.py       # 内容検証
├── logic_validator.py         # ロジック検証
├── consistency_validator.py   # 一貫性検証
├── recommendation_engine.py   # 推奨事項生成
└── validator_factory.py       # ファクトリーパターン
```

### 1.2 共通ユーティリティの作成

既に`file_io.py`が存在するが、追加の共通処理を統合：

```python
# src/utils/file_io.py に追加
class FileIOHelper:
    @staticmethod
    def save_numpy_compressed(data: np.ndarray, path: str) -> None:
        """NumPy配列を圧縮保存"""
        np.savez_compressed(path, data=data)

    @staticmethod
    def load_numpy_compressed(path: str) -> np.ndarray:
        """圧縮されたNumPy配列を読み込み"""
        return np.load(path)['data']

# src/utils/cache_manager.py (新規)
from functools import lru_cache
from typing import Any, Callable
import hashlib
import json

class CacheManager:
    """共通キャッシュ管理"""
    def __init__(self, max_size: int = 1000):
        self._cache = {}
        self._max_size = max_size

    def get_or_compute(self, key: str, compute_fn: Callable[[], Any]) -> Any:
        """キャッシュから取得または計算"""
        if key in self._cache:
            return self._cache[key]

        result = compute_fn()
        if len(self._cache) >= self._max_size:
            # LRU削除
            oldest = next(iter(self._cache))
            del self._cache[oldest]

        self._cache[key] = result
        return result
```

### 1.3 設定値の外部化

config.yamlの大幅な整理と天鳳形式特化：

```yaml
# 天鳳JSON形式専用設定
output:
  format: "tenhou_json"  # 固定値
  validation_enabled: true
  include_metadata: true
  pretty_print: false  # 本番はfalse

# パフォーマンス設定
performance:
  cache_size: 1000
  batch_size: 32
  max_workers: 4
  memory_limit_gb: 8

# 品質検証設定  
validation:
  min_confidence: 0.7
  max_error_rate: 0.05
  penalties:
    missing_field: 20
    wrong_type: 15
    invalid_structure: 70
```

## フェーズ2: パフォーマンス最適化（第3週）

### 2.1 並列処理の改善

#### parallel_ai_pipeline.py の最適化

```python
# src/pipeline/parallel_ai_pipeline.py
import asyncio
from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor
from typing import List, Dict, Any
import numpy as np

class OptimizedParallelAIPipeline(AIPipeline):
    """最適化された並列AIパイプライン"""

    def __init__(self, config_manager: ConfigManager):
        super().__init__(config_manager)
        self.process_pool = ProcessPoolExecutor(max_workers=self.config.max_workers)
        self.thread_pool = ThreadPoolExecutor(max_workers=self.config.max_workers * 2)

    async def process_frames_async(self, frames: List[np.ndarray]) -> List[PipelineResult]:
        """非同期フレーム処理"""
        tasks = []
        for i, frame in enumerate(frames):
            task = asyncio.create_task(self._process_frame_async(frame, i))
            tasks.append(task)

        results = await asyncio.gather(*tasks)
        return results

    def process_frames_batch_optimized(self, frames: List[np.ndarray], batch_size: int = 32) -> List[PipelineResult]:
        """最適化されたバッチ処理"""
        results = []

        # バッチを作成
        batches = [frames[i:i + batch_size] for i in range(0, len(frames), batch_size)]

        # GPU利用可能な場合は優先
        if torch.cuda.is_available():
            with torch.cuda.amp.autocast():  # 自動混合精度
                for batch in batches:
                    batch_results = self._process_batch_gpu(batch)
                    results.extend(batch_results)
        else:
            # CPU並列処理
            futures = []
            for batch in batches:
                future = self.process_pool.submit(self._process_batch_cpu, batch)
                futures.append(future)

            for future in futures:
                results.extend(future.result())

        return results
```

### 2.2 メモリ最適化

#### advanced_memory_optimizer.py の改善

```python
# src/optimization/advanced_memory_optimizer.py
import gc
import psutil
import resource
from memory_profiler import profile

class EnhancedMemoryOptimizer(AdvancedMemoryOptimizer):
    """強化されたメモリ最適化"""

    def __init__(self, config_manager: ConfigManager):
        super().__init__(config_manager)
        self.memory_limit_bytes = self.config.memory_limit_gb * 1024 * 1024 * 1024
        self._set_memory_limit()

    def _set_memory_limit(self):
        """メモリ制限を設定"""
        if hasattr(resource, 'RLIMIT_AS'):
            resource.setrlimit(resource.RLIMIT_AS, (self.memory_limit_bytes, self.memory_limit_bytes))

    @profile
    def optimize_numpy_arrays(self):
        """NumPy配列の最適化"""
        # 未使用配列の解放
        for obj in gc.get_objects():
            if isinstance(obj, np.ndarray) and obj.nbytes > 1024 * 1024:  # 1MB以上
                if sys.getrefcount(obj) == 2:  # 参照カウント2は未使用
                    del obj

        # メモリプールのクリア
        if hasattr(np, 'get_array_memory_pool'):
            np.get_array_memory_pool().free_all_blocks()

    def monitor_and_optimize(self):
        """リアルタイムメモリ監視と最適化"""
        memory_percent = psutil.virtual_memory().percent

        if memory_percent > 80:
            self.logger.warning(f"メモリ使用率が高い: {memory_percent}%")
            self.optimize_memory()

        if memory_percent > 90:
            self.logger.error("メモリ使用率が危険域に到達")
            self.aggressive_cleanup()
```

### 2.3 キャッシュ戦略の実装

```python
# src/utils/intelligent_cache.py
from functools import lru_cache
import pickle
import hashlib
from pathlib import Path

class IntelligentCache:
    """インテリジェントキャッシュシステム"""

    def __init__(self, cache_dir: Path = Path("cache"), max_memory_mb: int = 500):
        self.cache_dir = cache_dir
        self.cache_dir.mkdir(exist_ok=True)
        self.max_memory_mb = max_memory_mb
        self.memory_cache = {}
        self.disk_cache_index = {}

    def get_or_compute(self, key: str, compute_fn: Callable, use_disk: bool = True):
        """キャッシュから取得または計算"""
        # メモリキャッシュを確認
        if key in self.memory_cache:
            return self.memory_cache[key]

        # ディスクキャッシュを確認
        if use_disk and key in self.disk_cache_index:
            return self._load_from_disk(key)

        # 計算実行
        result = compute_fn()

        # キャッシュに保存
        self._save_to_cache(key, result, use_disk)

        return result

    def _save_to_cache(self, key: str, value: Any, use_disk: bool):
        """キャッシュに保存"""
        # サイズを確認
        size_mb = sys.getsizeof(value) / (1024 * 1024)

        if size_mb < 10:  # 10MB未満はメモリに保存
            self.memory_cache[key] = value
        elif use_disk:  # それ以上はディスクに保存
            self._save_to_disk(key, value)
```

## フェーズ3: アーキテクチャ改善（第4週）

### 3.1 天鳳JSON形式への完全移行

#### 削除対象コード
- MJSCORE形式関連のすべてのコード
- 出力形式選択ロジック
- 不要な変換処理

#### 新規実装

```python
# src/output/tenhou_optimized_formatter.py
import orjson  # 高速JSONライブラリ
from dataclasses import dataclass, asdict
from typing import List, Dict, Any

@dataclass
class TenhouOptimizedFormatter:
    """最適化された天鳳JSONフォーマッター"""

    def __init__(self, config_manager: ConfigManager):
        self.config = config_manager
        self.cache = IntelligentCache()

    def format_game_record(self, game_data: GameState) -> str:
        """高速天鳳JSON変換"""
        # キャッシュキーを生成
        cache_key = self._generate_cache_key(game_data)

        # キャッシュから取得または変換
        tenhou_data = self.cache.get_or_compute(
            cache_key,
            lambda: self._convert_to_tenhou_format(game_data)
        )

        # 高速JSON変換
        return orjson.dumps(
            tenhou_data,
            option=orjson.OPT_SERIALIZE_NUMPY | orjson.OPT_SORT_KEYS
        ).decode('utf-8')

    def _convert_to_tenhou_format(self, game_data: GameState) -> Dict[str, Any]:
        """最適化された変換処理"""
        return {
            "title": self._generate_title(game_data),
            "name": self._get_player_names(game_data),
            "rule": self._get_rule_settings(),
            "log": self._convert_game_log_optimized(game_data),
            "sc": self._get_final_scores(game_data),
            "owari": self._generate_end_info(game_data)
        }
```

### 3.2 依存性注入の実装

```python
# src/core/dependency_injection.py
from typing import TypeVar, Type, Dict, Any
from abc import ABC

T = TypeVar('T')

class DIContainer:
    """依存性注入コンテナ"""

    def __init__(self):
        self._services: Dict[Type, Any] = {}
        self._singletons: Dict[Type, Any] = {}

    def register(self, interface: Type[T], implementation: Type[T], singleton: bool = True):
        """サービスを登録"""
        self._services[interface] = (implementation, singleton)

    def resolve(self, interface: Type[T]) -> T:
        """サービスを解決"""
        if interface in self._singletons:
            return self._singletons[interface]

        if interface not in self._services:
            raise ValueError(f"Service {interface} not registered")

        implementation, is_singleton = self._services[interface]
        instance = self._create_instance(implementation)

        if is_singleton:
            self._singletons[interface] = instance

        return instance

    def _create_instance(self, implementation: Type[T]) -> T:
        """インスタンスを作成"""
        # コンストラクタの引数を解析して依存関係を注入
        init_signature = inspect.signature(implementation.__init__)
        kwargs = {}

        for param_name, param in init_signature.parameters.items():
            if param_name == 'self':
                continue
            if param.annotation != param.empty:
                kwargs[param_name] = self.resolve(param.annotation)

        return implementation(**kwargs)

# 使用例
container = DIContainer()
container.register(ConfigManager, ConfigManager)
container.register(IDetector, TileDetector)
container.register(IClassifier, TileClassifier)
container.register(IFormatter, TenhouOptimizedFormatter)
```

### 3.3 イベント駆動アーキテクチャ

```python
# src/core/event_system.py
from typing import Callable, List, Dict, Any
from enum import Enum
import asyncio

class EventType(Enum):
    """イベントタイプ"""
    FRAME_PROCESSED = "frame_processed"
    TILE_DETECTED = "tile_detected"
    GAME_STATE_CHANGED = "game_state_changed"
    VALIDATION_COMPLETED = "validation_completed"
    ERROR_OCCURRED = "error_occurred"

class Event:
    """イベントクラス"""
    def __init__(self, event_type: EventType, data: Any):
        self.type = event_type
        self.data = data
        self.timestamp = datetime.now()

class EventBus:
    """イベントバス"""

    def __init__(self):
        self._handlers: Dict[EventType, List[Callable]] = {}
        self._async_handlers: Dict[EventType, List[Callable]] = {}

    def subscribe(self, event_type: EventType, handler: Callable, is_async: bool = False):
        """イベントハンドラを登録"""
        if is_async:
            if event_type not in self._async_handlers:
                self._async_handlers[event_type] = []
            self._async_handlers[event_type].append(handler)
        else:
            if event_type not in self._handlers:
                self._handlers[event_type] = []
            self._handlers[event_type].append(handler)

    def publish(self, event: Event):
        """イベントを発行"""
        # 同期ハンドラ実行
        if event.type in self._handlers:
            for handler in self._handlers[event.type]:
                try:
                    handler(event)
                except Exception as e:
                    self._handle_error(e, handler, event)

        # 非同期ハンドラ実行
        if event.type in self._async_handlers:
            asyncio.create_task(self._run_async_handlers(event))

    async def _run_async_handlers(self, event: Event):
        """非同期ハンドラを実行"""
        tasks = []
        for handler in self._async_handlers.get(event.type, []):
            task = asyncio.create_task(handler(event))
            tasks.append(task)

        await asyncio.gather(*tasks, return_exceptions=True)
```

## フェーズ4: テスト改善（第5週）

### 4.1 テストカバレッジの向上

#### 低カバレッジモジュールへの対応

```python
# tests/test_gpu_optimizer.py
import pytest
from unittest.mock import Mock, patch
import torch

class TestGPUOptimizer:
    """GPUオプティマイザーのテスト"""

    @pytest.fixture
    def gpu_optimizer(self):
        with patch('torch.cuda.is_available', return_value=True):
            config_manager = Mock()
            config_manager.get_config.return_value = {
                'system': {'gpu_enabled': True}
            }
            return GPUOptimizer(config_manager)

    def test_optimize_gpu_memory(self, gpu_optimizer):
        """GPUメモリ最適化のテスト"""
        with patch('torch.cuda.empty_cache') as mock_empty_cache:
            gpu_optimizer.optimize_gpu_memory()
            mock_empty_cache.assert_called_once()

    def test_allocate_gpu_memory(self, gpu_optimizer):
        """GPUメモリ割り当てのテスト"""
        with patch('torch.cuda.set_per_process_memory_fraction') as mock_set_memory:
            gpu_optimizer.allocate_gpu_memory(0.8)
            mock_set_memory.assert_called_once_with(0.8)
```

### 4.2 統合テストの強化

```python
# tests/integration/test_end_to_end_optimized.py
class TestEndToEndOptimized:
    """最適化されたエンドツーエンドテスト"""

    @pytest.fixture
    def test_system(self):
        """テストシステムのセットアップ"""
        container = DIContainer()
        # サービス登録
        container.register(ConfigManager, ConfigManager)
        container.register(VideoProcessor, VideoProcessor)
        container.register(AIPipeline, OptimizedParallelAIPipeline)
        container.register(GamePipeline, GamePipeline)
        container.register(SystemIntegrator, SystemIntegrator)

        return container.resolve(SystemIntegrator)

    @pytest.mark.integration
    def test_complete_workflow_performance(self, test_system, benchmark):
        """完全ワークフローのパフォーマンステスト"""
        test_video = "tests/fixtures/test_mahjong_game.mp4"

        result = benchmark(
            test_system.process_video_complete,
            test_video,
            "output_test.json"
        )

        assert result['success']
        assert result['processing_time'] < 60  # 1分以内
        assert result['quality_score'] > 0.9
```

## 実装スケジュール

### 第1週: 基礎リファクタリング
- Day 1-2: 巨大クラスの分割設計
- Day 3-4: 共通ユーティリティの実装
- Day 5: 設定ファイルの整理

### 第2週: クラス分割実装
- Day 1-2: model_evaluator.pyの分割
- Day 3-4: quality_validator.pyの分割  
- Day 5: 分割後のテスト修正

### 第3週: パフォーマンス最適化
- Day 1-2: 並列処理の改善
- Day 3-4: メモリ最適化の実装
- Day 5: キャッシュシステムの実装

### 第4週: アーキテクチャ改善
- Day 1-2: 天鳳形式への完全移行
- Day 3: 依存性注入の実装
- Day 4-5: イベント駆動システムの実装

### 第5週: テストと品質保証
- Day 1-2: 低カバレッジモジュールのテスト追加
- Day 3-4: 統合テストの強化
- Day 5: パフォーマンステストと最終確認

## 成功指標

### 定量的指標
- **コード行数**: 各クラス500行以下（現在の898行から削減）
- **テストカバレッジ**: 80%以上（現在の54.19%から向上）
- **処理速度**: 20-30%向上
- **メモリ使用量**: 20%削減
- **CI実行時間**: 3分以内（現在の4-5分から短縮）

### 定性的指標
- 単一責任原則の遵守
- 疎結合アーキテクチャの実現
- 天鳳JSON形式への完全特化
- 保守性・拡張性の向上

## リスクと対策

### リスク
1. **後方互換性の破壊**: 既存APIの変更
2. **一時的なパフォーマンス低下**: リファクタリング中の性能劣化
3. **テストの大量修正**: 構造変更に伴うテスト修正

### 対策
1. **段階的移行**: 新旧インターフェースの並存期間を設定
2. **継続的ベンチマーク**: 各変更前後でパフォーマンス測定
3. **テスト駆動開発**: テストを先に修正してからリファクタリング

## まとめ

本リファクタリング計画により、以下の改善が期待されます：

1. **保守性の大幅向上**: 巨大クラスの分割により、理解と修正が容易に
2. **パフォーマンスの改善**: 並列処理とメモリ最適化により処理速度向上
3. **テスト品質の向上**: カバレッジ80%以上により、信頼性向上
4. **将来の拡張性**: 疎結合アーキテクチャにより、新機能追加が容易に

段階的な実装により、リスクを最小限に抑えながら着実な改善を実現します。

<function_calls>
<invoke name="TodoWrite">
<parameter name="todos">[{"id": "refactor-plan-1", "content": "\u73fe\u5728\u306e\u30b3\u30fc\u30c9\u30d9\u30fc\u30b9\u306e\u72b6\u614b\u3092\u5206\u6790\u3057\u3066\u30ea\u30d5\u30a1\u30af\u30bf\u30ea\u30f3\u30b0\u5bfe\u8c61\u3092\u7279\u5b9a", "status": "completed", "priority": "high"}, {"id": "refactor-plan-2", "content": "\u30ea\u30d5\u30a1\u30af\u30bf\u30ea\u30f3\u30b0\u8a08\u753b\u66f8\u3092\u4f5c\u6210", "status": "in_progress", "priority": "high"}]
